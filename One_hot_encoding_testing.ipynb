{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One hot encoding testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LaU0b0ZdF2k"
      },
      "outputs": [],
      "source": [
        "from os import getcwd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_one_hot(feature, label):\n",
        "    # Encode the labels to one-hot using tf.one_hot with depth equal to total \n",
        "    # number of classes here which are rock, paper and scissors\n",
        "    indices = label\n",
        "    depth = 3\n",
        "    one_hot = tf.one_hot(indices, depth)\n",
        "    return feature, one_hot\n",
        "\n",
        "# TESTING THE FUNCTION \n",
        "_,one_hot = my_one_hot([\"a\",\"b\",\"c\",\"a\"],[1,2,3,1])\n",
        "print(one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akpQG2GJdHCb",
        "outputId": "8cab019c-c315-459a-e3c6-dc8818cc85c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 1. 0.]], shape=(4, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: Loading the rock, paper and scissors train and test dataset using tfds.load. \n",
        "\n",
        "# Use data_dir=filepath as the dataset is already downloaded for you\n",
        "\n",
        "filePath = f\"{getcwd()}/data\"\n",
        "\n",
        "train_data = tfds.load('rock_paper_scissors', split='train', data_dir=filePath, as_supervised=True)\n",
        "val_data = tfds.load('rock_paper_scissors', split='test', data_dir=filePath, as_supervised=True)\n",
        "\n",
        "# Testing train_data and val_data if loaded correctly\n",
        "    \n",
        "train_data_len = len(list(train_data))\n",
        "val_data_len = len(list(val_data))\n",
        "\n",
        "print(train_data_len)\n",
        "print(val_data_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag5qmr1EdLZ_",
        "outputId": "49af7de1-5f1d-44cc-d54b-c5ef58326c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2520\n",
            "372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: one-hot encode the train and validation labels using the function you defined earlier\n",
        "\n",
        "# HINT - use map function https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map\n",
        "\n",
        "train_data =  train_data.map(my_one_hot)\n",
        "val_data = val_data.map(my_one_hot)\n",
        "\n",
        "print(type(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TTCf_QEdN75",
        "outputId": "dd8e4833-cbea-4182-e8b9-ab2b9084d9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: Check the information about the dataset to see the dataset image shape\n",
        "\n",
        "# HINT: Use with_info=True and data_dir\n",
        "_,info = tfds.load(# YOUR CODE HERE)\n",
        "\n",
        "# DO NOT EDIT THIS\n",
        "print(info.features['image'].shape)"
      ],
      "metadata": {
        "id": "1fR6qLr5dapG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EXERCISE: Train a simple CNN model on the dataset\n",
        "\n",
        "train_batches = train_data.shuffle(100).batch(10)\n",
        "validation_batches = val_data.batch(32)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=# YOUR CODE HERE),                       \n",
        "    # YOUR CODE HERE - Add a maxpool2d layer with kernel (2,2) \n",
        "    # YOUR CODE HERE - Add a flatten layer                                           \n",
        "    tf.keras.layers.Dense(# YOUR CODE HERE)  # Remember there are 3 classes to classify and to use proper activation\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0NVOjg_-dchu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JN-ahpuIdeal"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}